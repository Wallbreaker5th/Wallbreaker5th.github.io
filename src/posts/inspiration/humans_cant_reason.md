---
date: 2025-06-09
category:
    - 突发奇想
tag:
    - AI
    - AI - LLM
title: 思维的幻象：从任务复杂度的视角理解生物体的能力局限性
excerpt: 通过对生物体在不同复杂度任务中的表现进行系统性研究，揭示其推理和执行能力的根本局限性。
---

[English Version](humans_cant_reason_en.html)

G. E. Mini\* †, Gipi Tee\*, C. L. Auden\*, Dee P. Sekar, and Robert K. Grok<br>
\* The Orchard Institute for Cognitive Studies<br>
† 文章使用 Gemini 2.5 Pro 0605 生成

## 摘要
近期对所谓的“智能”生物体（Biological Agents, BAs），即人类的观察表明，他们在需要规划、推理和指令遵循的任务中展现出明显的能力。然而，其内部认知过程的基本属性和局限性仍未被充分理解。当前的评估范式，如学术考试或现实世界的问题解决，受到不可控变量和广泛数据污染（即“先验经验”）的影响，无法深入洞察其认知核心机制。在这项工作中，我们借助一个可控的纸笔环境，系统性地研究了这些空白。该环境允许我们精确操控组合复杂度，同时保持一致的逻辑结构。这种设置不仅能分析最终任务的成功率，还能分析其内部的“思维轨迹”（即书面输出）。通过实验，我们表明，当复杂度超过一个惊人的低阈值时，生物体（BAs）的准确率会完全崩溃。此外，他们表现出一种反直觉的扩展极限：他们的执行努力（以时间和专注度衡量）随任务复杂度上升到某个点后，便会急剧下降，即使有充足的时间。我们发现，生物体在精确计算方面存在深远的局限性，无法执行一个简单、明确定义的算法。对其书面轨迹的分析揭示了其推理的不一致性和状态维持的失败，这揭示了他们的局限性，并对其真实的认知能力提出了关键问题。

## 1. 引言

长期以来，生物体（BAs），即“人类”，被视为推理和指令遵循任务的黄金标准。他们建造结构、解决谜题和遵循食谱的能力，导致了这样一个普遍的假设：他们拥有一个强大、可泛化的“思维”机制。然而，这种观察到的表现究竟是源于真正的算法推理，还是源于一系列熟练掌握的启发式方法，仍然是一个关键的辩论点。

我们认为，当前评估范式的局限性导致了系统性分析的缺失。现实世界的任务被先验知识严重污染，并且不允许对复杂度进行受控操作。为了更严谨地理解这些智能体的推理行为，我们需要能够进行受控实验的环境。

在本研究中，我们通过任务复杂度的视角，探索生物体的核心机制。我们引入了“序列整数转录”（Sequential Integer Transcription, SIT）任务，这是一个简单但可扩展的谜题环境。SIT任务要求生物体：（1）理解一个简单的指令，（2）维持一个内部状态（当前数字），以及（3）重复执行一个基本的算法步骤（加一）。这种受控环境使我们能够对照精确定义的基准来衡量其表现，并详细分析其失败模式。

## 2. 实验与结果

### 2.1 实验设置

我们的实验在一组成年生物体上进行。每位受试者都获得了标准的笔和充足的纸张。他们被给予一个单一、明确的指令：“用笔依次写下从1到2<sup>n</sup>（包含2<sup>n</sup>）的所有整数，不能有任何错误或遗漏。” 任务的组合复杂度通过调整整数*n*来变化。任务成功的定义是完美转录、无任何错误的序列。

### 2.2 在低复杂度下的性能崩溃

我们的研究揭示了一个鲜明而确凿的发现：当复杂度超过一个适中的阈值时，生物体无法可靠地遵循简单的算法指令。

如我们的结果所示，对于较低的*n*值（例如 *n* = 5，即写到32），其表现良好。然而，随着复杂度的增加，我们观察到其性能迅速且完全地崩溃。当复杂度为 *n* = 9（即写到512）时，成功率骤降至约20%。当复杂度 *n* ≥ 10（即写到1024）时，成功率趋近于零。这种情况的发生，尽管任务规则保持恒定且简单。无法执行一个简单的重复性算法，指向了生物体处理架构中的根本性缺陷。有趣的是，少数异常的生物体在 *n* = 10 时成功了，但这似乎是异常值，而非可扩展能力的标志。

### 2.3 努力程度的反直觉扩展

我们分析了生物体的执行努力，以任务放弃或出现首个错误前所花费的时间来衡量。对于中低复杂度（*n* = 6 到 *n* = 8），努力程度与问题规模成正比，受试者花费的时间更长，显得更专注。

然而，当复杂度超过 *n* = 9 的临界点时，我们观察到一个反直觉的逆转。当面对高复杂度任务（例如 *n* = 12）时，生物体放弃任务的速度要快得多。尽管有充足的时间和资源，这种努力程度的下降表明，智能体的动机或执行监控系统存在严重故障。智能体选择了“放弃”，而不是投入更多的计算资源，这暗示了一种硬编码的扩展局限性。

### 2.4 书面轨迹分析

为了理解生物体*如何*失败，我们分析了他们的书面输出，即“推理轨迹”。我们识别了几类关键错误：

*   **状态丢失：** 最常见的错误是跳过一个或多个整数（例如，“...147, 148, 150...”）。这表明其未能正确维持和更新内部状态（“当前数字”）。
*   **执行失败：** 频繁的错误涉及数字转录不正确，尤其是在“进位”事件中（例如，写成“199, 200, 202”或甚至“199, 100”）。这凸显了其在符号操作上的根本弱点。
*   **循环错误：** 几名生物体进入了短循环，重复一个数字或一小段数字序列（例如，“...341, 342, 341, 342...”），表明其前进机制发生了灾难性故障。

这些错误模式表明，生物体并非在执行一个明确的算法。相反，他们的输出似乎是由一个脆弱的、启发式的过程生成的，该过程在持续负载下极易崩溃。

## 3. 结论

在本文中，我们使用一个受控的纸笔环境，从任务复杂度的视角系统性地检验了生物体。我们的发现揭示了其能力的根本局限性。尽管普遍认为他们具有智能，但生物体无法可靠地执行简单的算法指令，在低复杂度下就表现出完全的性能崩溃。我们发现了一个反直觉的扩展极限，即当问题变得足够困难时，其努力程度反而会下降。

我们对其书面轨迹的分析，揭示了其在状态管理和符号操作方面的系统性失败。这些见解挑战了“人类拥有真正的、可泛化的推理能力”这一主流假设。我们断言，通常被称为“思考”或“推理”的东西，实际上可能是一种幻象——一个由后天习得的启发式方法拼凑而成的集合，它在熟悉的、低复杂度的环境中有效，但本质上是脆弱且不可扩展的。这些结果为未来研究生物认知的真实本质铺平了道路。
